# The API specifies which type of component this is.
# It contains specifications for:
#   - The input/output files
#   - Common parameters
#   - A unit test
__merge__: ../../api/comp_method.yaml

# A unique identifier for your component (required).
# Can contain only lowercase letters or underscores.
name: cellplm
# A relatively short label, used when rendering visualisations (required)
label: cellplm
# A one sentence summary of how this method works (required). Used when 
# rendering summary tables.
summary: "A foundation model pre-trained with cells as tokens."
# A multi-line description of how this component works (required). Used
# when rendering reference documentation.
description: |
  CellPLM is a pre-trained language model specifically designed for single-cell analysis that leverages the principles of natural language processing (NLP) to understand and process single-cell gene expression data. 
references:
  # doi: 
  #   - https://openreview.net/forum?id=BKXvPDekud
  bibtex:
    - |
      @inproceedings{
      wen2024cellplm,
      title={Cell{PLM}: Pre-training of Cell Language Model Beyond Single Cells},
      author={Hongzhi Wen and Wenzhuo Tang and Xinnan Dai and Jiayuan Ding and Wei Jin and Yuying Xie and Jiliang Tang},
      booktitle={The Twelfth International Conference on Learning Representations},
      year={2024},
      url={https://openreview.net/forum?id=BKXvPDekud}
      }
links:
  # URL to the documentation for this method (required).
  documentation: https://github.com/OmicsML/CellPLM
  # URL to the code repository for this method (required).
  repository: https://github.com/OmicsML/CellPLM


info:
  method_types: [embedding]
  preferred_normalization: counts

# arguments:
#   - name: --model
#     type: string
#     description: String giving the scGPT model to use
#     choices: ["cellplm"]
#     default: "cellplm"
#   - name: --n_hvg
#     type: integer
#     default: 3000
#     description: Number of highly variable genes to use.

resources:
  - type: python_script
    path: script.py
  - path: /src/utils/read_anndata_partial.py

engines:
  - type: docker
    image: openproblems/base_pytorch_nvidia:1.0.0
    # TODO: Try to find working installation of flash attention (flash-attn<1.0.5)
    setup:
      - type: python
        pypi:
          - torch==1.13.0
          - gdown
          - scgpt # Install from PyPI to get dependencies
          - cellplm
          - scanpy

runners:
  - type: executable
  - type: nextflow
    directives:
      label: [midtime, midmem, midcpu, gpu]
